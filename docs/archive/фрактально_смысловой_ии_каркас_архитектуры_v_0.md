# Фрактально-смысловой ИИ — каркас архитектуры (v0.1)

## 0) Цель и принципы

**Цель:** движок, который на лету обрабатывает данные, формирует «опыт» как отдельные пакеты, обучается из опыта, реагирует на стимулы и планирует действия.

**Принципы:**

1. **Разделение потоков и опыта:** онлайн-обработка отделена от долговременного хранилища опыта (Experience Store). Опыт — иммутабельные пакеты + индексы.
2. **Фрактальная модель смыслов:** единица представления — *точка* с 3 осями и 8 комбинациями знаков; уровни: точка → токен (8 точек) → слово (8 токенов) → фрейм → сцена → …
3. **Универсальные 8 характеристик:** каждая — плоскость смыслов (собственный тройной вектор-«ось»). Используются на всех уровнях.
4. **Двоичная реактивность + рефлексия:** быстрый реактивный контур (R-loop) и медленный рефлексивный контур (F-loop) для обучения, обобщения, планирования.
5. **Композиционность и трассируемость:** любой вывод восстанавливается как граф причин (explainability by construction).

---

## 1) Общий обзор модулей

- **Ingress & Adapters** — приём мультимодальных данных (текст, аудио, сенсоры, события API). Нормализация в единый формат событий.
- **Encoder (Fractal Encoder)** — кодирует входы в фрактально-смысловые координаты (FSC). Выдаёт *семантические точки/токены* с уровнем уверенности.
- **Working Memory (WM)** — кратковременное хранилище активного контекста (скользящее окно + приоритетное внимание).
- **Reactive Policy (R-Policy)** — быстрые реакции на основе текущего контекста WM + ближайшего опыта (k-NN по индексам).
- **Planner/Deliberator (F-Policy)** — медленное рассуждение: построение планов, симуляция альтернатив, выбор стратегии.
- **World Model / Simulator** — предсказывает последствия действий в FSC-пространстве.
- **Experience Store (ES)** — долговременная память опыта: иммутабельные «пакеты опыта» + граф индексов.
- **Indexer** — многомерные индексы (ANN/IVF/HNSW) по FSC-векторам и по символам (граф сущностей/отношений).
- **Reflector (Consolidation)** — свёртка онлайновых следов в стабильные пакеты опыта; извлечение правил/шаблонов.
- **Trainer** — дообучение энкодера/политик/моделей мира на новых пакетах; off-policy и онлайн-обучение.
- **Safety & Goals** — ограничения, предпочтения, система ценностей и фильтры.
- **Actuators/Tools** — исполнение действий (генерация текста, API-вызовы, управление агентами/роботами).
- **Telemetry & Causality Graph** — трассировка решений, метрики, реплеи.

---

## 2) Потоки данных (высокоуровнево)

1. **Событие** → Ingress → Adapter → *UnifiedEvent*.
2. UnifiedEvent → **Fractal Encoder** → *FSC-Sequence* (точки/токены/фреймы).
3. FSC-Sequence → **WM** (приоритеты, забывание, внимание).
4. Параллельно: **Nearest Experience Query** в ES (ANN + символический граф).
5. **R-Policy** производит быструю реакцию (если триггеры/сроки) → Actuators.
6. **F-Policy + World Model** строят план (если время позволяет) → пошаговые действия.
7. **Reflector** агрегирует следы (Trace) → **Пакеты опыта** → индексация.
8. **Trainer** периодически дообучает модули.

ASCII-схема:
```
[Sources]→Adapters→Encoder→WM→{R-Policy→Act}
                              ↘→{F-Policy+WorldModel→Plan→Act}
  ES↔Indexer←Reflector←Traces←Telemetry
          ↑                 ↓
        Trainer←────────────┘
```

---

## 3) Фрактально-смысловые координаты (FSC)

- **Единица:** *Point* = (a,b,c), где каждая ось ∈ {−, +}, с величиной |v|∈[0,1] и уверенностью p∈[0,1]. Комбинаций знаков — 8.
- **Характеристика (Plane):** тройка осей для одной из 8 универсальных характеристик.
- **Уровни:**
  - *Point* — примитивное ощущение/признак.
  - *Token* — 8 точек.
  - *Word/Concept* — 8 токенов.
  - *Frame* — контекстная структура (роли, связи).
  - *Scene* — композиция фреймов.
- **Операции:** свёртка (↓), развёртка (↑), проекция (на характеристики), инверсия знаков, конкатенация по иерархии.

---

## 4) Опыт как пакеты (Experience Packages, XP)

**Формат XP:**

- `xp_id`: UUID, версия, timestamp.
- `signature`: компактный FSC-вектор сцены (+ распределение по 8 характеристикам).
- `trace`: причинный граф: входы → WM-состояния → выбранные действия → результаты.
- `lessons`: извлечённые правила/шаблоны (if-then, протоколы, планы).
- `metrics`: успех/стоимость/риски, уверенности.
- `links`: связи с другими XP (граф опыта).
- `privacy/safety`: метки ограничений.

**Свойства:** иммутабельность, адресуемость, версия; индексация как по вектору (ANN), так и по символам (граф сущностей/отношений).

---

## 5) Рабочая память (WM)

- Кольцевой буфер фреймов с приоритетным вытеснением (top-k by salience).
- Механизмы внимания: новизна, предсказательная ошибка, целевая релевантность, аффект.
- «Слоты» под активные гипотезы (что происходит? какие цели? какие риски?).

---

## 6) Политики поведения

**R-Policy (реактивная):**

- Вход: WM-срез + ближайшие XP.
- Выход: немедленное действие; эвристики + небольшая нейросеть.
- Использование правил из `lessons` (прецеденты, шаблоны).

**F-Policy (рефлексивная/планировщик):**

- Поиск планов через MCTS/Beam в пространстве FSC-актов.
- Оценка планов через World Model; оптимизация по целям/ограничениям.
- Может переписать/отменить реактивный отклик, если время позволяет.

---

## 7) Модель мира (World Model)

- Обучается предсказывать переходы в FSC-пространстве: *state_t, act → state_{t+1}*.
- Поддерживает симуляцию ветвлений; даёт градиенты новизны/рисков.

---

## 8) Рефлексия и консолидация (Reflector)

- Сбор онлайновых «следов решения» (Traces) с WM.
- Свертка в XP: дедупликация, извлечение причинных цепочек, выделение уроков.
- Обновление индексов и графа опыта.

---

## 9) Обучение (Trainer)

- **Онлайн:** fine-tune Encoder/R-Policy по новому распределению.
- **Off-policy:** реплей XP с приоритетом по новизне/ошибке.
- **Self-supervised:** маскировка/восстановление FSC-последовательностей; контрастивные задачи по XP.
- **Rule distillation:** дистилляция lessons в лёгкие правила/промпты для R-Policy.

---

## 10) Безопасность и ценности (Safety & Goals)

- Ограничители действий (hard constraints) + проверка планов.
- Чёрные списки инструментов/состояний, каппинг рисков.
- Канал целей: приоритеты, этические параметры, пользовательские политики.

---

## 11) Индексация и поиск

- ANN (HNSW/IVF) по `signature` XP и по объектам FSC-фреймов.
- Символический граф сущностей/отношений (property graph) с быстрыми путевыми запросами.
- Гибридные запросы: (векторная близость ∧ логические фильтры).

---

## 12) API-грани

- **/ingress/event** — приём событий.
- **/act/** — исполнение действия/инструмента.
- **/wm/snapshot** — диагностический снимок WM.
- **/xp/query** — поиск опыта.
- **/reflect/commit** — форсировать консолидацию.
- **/train/schedule** — план обучения.

---

## 13) Минимальный MVP (1–2 спринта)

1. Фиктивные источники (текст), простой Adapter.
2. Прототип Fractal Encoder: маппинг токенов → FSC (через обучаемую эмбеддинг-матрицу + знаковые головы).
3. WM с приоритетным буфером и простыми метриками салинса.
4. ES на базе векторного индекса (FAISS/HNSWlib) + лёгкий граф (SQLite/NetworkX или Neo4j позже).
5. R-Policy: k-NN по XP + правила-уроки (ручные шаблоны сначала).
6. Reflector: сбор Trace → XP JSON + индексация.
7. Простейший World Model (n-gram/малый трансформер) для предсказания следующего FSC-среза.
8. Telemetry + воспроизводимость (seeded runs, логи причин).

---

## 14) Псевдокод (сигнатуры)

```pseudo
struct Point { sign: (+/−,+/−,+/−); mag: [0,1]^3; conf: float }
struct Token { points: Point[8]; conf: float }
struct Frame { tokens: Token[≤N]; roles: Map<Role, Ref>; conf: float }
struct Scene { frames: Frame[≤M]; conf: float }

struct XP {
  id: UUID; ts: Time;
  signature: Vector[d]; // проекция сцены
  trace: CausalGraph; lessons: RuleSet; metrics: Metrics;
  links: Edge[]; policy: Meta;
}

function process(event): Action {
  u = adapt(event)
  s = encode_FSC(u) // Scene
  WM.update(s)
  nbrs = ES.query(simkey=signature(s), k=K)
  a_fast = RPolicy(s, nbrs)
  if deadline_short(): return act(a_fast)
  plans = PlanSearch(s, goals, nbrs)
  scored = evaluate_with_world_model(plans)
  a = select(scored, constraints)
  return act(a)
}

on_tick() {
  trace = Telemetry.flush()
  xp = Reflector.consolidate(trace)
  ES.insert(xp); Indexer.update(xp)
}
```

---

## 15) Формулировка 8 базовых характеристик (рабочая версия)
>
> Место для твоих финальных определений. Временно:

1. **Энергия/Интенсивность** (активация ↔ подавление; устойчивость; импульсность).
2. **Направленность/Воля** (стремление ↔ избегание; внутрь ↔ наружу; согласованность).
3. **Структура/Порядок** (детерминизм ↔ стохастика; иерархия; симметрия).
4. **Информация/Ясность** (сигнал ↔ шум; определённость; разрешение).
5. **Отношение/Этика** (сотрудничество ↔ конкуренция; доверие; ответственность).
6. **Контекст/Границы** (локальность ↔ глобальность; масштаб; открытость).
7. **Динамика/Время** (темп; инерция; обратимость).
8. **Материальность/Ресурсы** (стоимость; дефицит; устойчивость).

Каждая характеристика — три оси со знаковостью (±) и нормируемой величиной; применяется на всех уровнях.

---

## 16) Метрики успеха

- Время реакции (P95), доля корректных действий без планирования.
- Качество планов (reward/step, риск, соблюдение ограничений).
- Консистентность уроков (повторяемость правил в XP).
- Объяснимость (средняя длина причинной цепи до наблюдаемого эффекта).

---

## 17) Риски и узкие места

- Сложность определения 8 универсальных характеристик (требует итераций и эмпирики).
- Баланс реактивности и рефлексии при жёстких дедлайнах.
- Согласование символического графа и векторных индексов.
- Контроль дрейфа при онлайн-обучении.

---

## 18) Следующие шаги

1. Зафиксировать формулировки 8 характеристик (рабочая версия → v1.0).
2. Выбрать формат XP (JSON Schema) и индексы.
3. Реализовать прототип Encoder→WM→ES→R-Policy→Reflector (MVP).
4. Определить 5–7 сценариев для ранних тестов (реактивные/плановые).
5. Ввести базовую систему целей/ограничений.
