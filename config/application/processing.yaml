# config/application/processing.yaml

# Конфигурация модуля обработки данных
processing:
  # Общие настройки
  environment: "development"  # development/staging/production
  log_level: "INFO"          # Уровень логирования
  
  # Настройки энкодера (преобразование в токены)
  encoder:
    enabled: true
    type: "default"           # Тип энкодера (default/advanced/custom)
    batch_size: 32            # Размер батча для пакетной обработки
    max_workers: 4            # Максимальное количество воркеров
    input_normalization: true  # Нормализация входных данных
    normalization_range: [-1.0, 1.0]  # Диапазон нормализации
    
    # Настройки кэширования
    cache:
      enabled: true
      max_size: 10000         # Максимальное количество закодированных элементов
      ttl: 3600               # Время жизни кэша в секундах
    
    # Настройки производительности
    performance:
      use_jit: true           # Использовать JIT-компиляцию
      precision: "float32"     # Точность вычислений (float32/float16)
      
    # Обработка ошибок
    error_handling:
      max_retries: 3          # Максимальное количество попыток
      retry_delay: 0.1        # Задержка между попытками (сек)
      fallback_to_default: true  # Использовать значения по умолчанию при ошибке

  # Настройки декодера (преобразование из токенов)
  decoder:
    enabled: true
    type: "default"           # Тип декодера (default/beam_search/sampling)
    beam_width: 4             # Ширина луча для beam search
    max_length: 100           # Максимальная длина декодируемой последовательности
    temperature: 0.7          # Температура для сэмплирования
    top_k: 50                 # Ограничение на топ-k токенов
    top_p: 0.9                # Ограничение на кумулятивную вероятность
    
    # Постобработка
    postprocessing:
      remove_special_tokens: true
      trim_whitespace: true
      normalize_whitespace: true

  # Движок интуиции (нейросетевая модель)
  intuition_engine:
    enabled: false
    model_path: "models/intuition_model.pt"
    model_type: "transformer"  # Тип модели (transformer/rnn/gpt-like)
    device: "auto"             # Устройство для вывода (auto/cpu/cuda)
    
    # Настройки кэширования
    cache:
      enabled: true
      size: 1024               # Размер кэша
      strategy: "lru"          # Стратегия вытеснения (lru/lfu)
    
    # Настройки вывода
    inference:
      max_batch_size: 16
      max_sequence_length: 512
      use_half_precision: true
      
    # Мониторинг
    monitoring:
      enabled: true
      metrics_interval: 60     # Интервал сбора метрик (сек)
      track_latency: true      # Отслеживать задержки
      track_memory: true       # Отслеживать использование памяти

  # Пайплайны обработки
  pipelines:
    default:
      - "normalize_input"
      - "encode"
      - "process"
      - "decode"
      - "postprocess"
    
    fast_inference:
      - "encode"
      - "process"
      - "decode"

  # Настройки отладки
  debug:
    log_processing_steps: false
    validate_inputs: true
    validate_outputs: true
    trace_processing: false    # Трассировка выполнения пайплайнов
